{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Library Setup__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "import ibm_db\n",
    "import ibm_db_dbi\n",
    "from django.shortcuts import get_object_or_404\n",
    "from boto.s3.connection import S3Connection\n",
    "from boto.s3.key import Key\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check current directory\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "code_folding": [
     1,
     235,
     247
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import extract and de-dup\n",
    "def f_import_extract_and_dedup(import_filename, dedup=False, zipped=True):\n",
    "    \n",
    "    # import extract\n",
    "    key = import_filename \n",
    "    if zipped==True:\n",
    "        obj = client.get_object(Bucket='dataview-systems-prod', Key=key)\n",
    "        data = pd.read_csv(io.BytesIO(obj['Body'].read()), compression = 'zip', sep = ';')\n",
    "    else:\n",
    "        data = pd.read_csv(key, sep=';')\n",
    "    \n",
    "    # indexing\n",
    "    data['extract_idx'] = range(len(data))\n",
    "    \n",
    "    # replace missing with other values to avoid mistakes in de-dup due to numpy ignoring NaN\n",
    "    data.loc[data.SELECTED_LOAN_AMT.isnull(),'SELECTED_LOAN_AMT'] = -1\n",
    "    data.loc[data.CL_1_CF_score.isnull(), 'CL_1_CF_score'] = -1\n",
    "    data.loc[data.DEC_CREDIT_BUREAU_USED.isnull(), 'DEC_CREDIT_BUREAU_USED'] = 'No Credit Bureau Used'\n",
    "    data.loc[data.DEC_CHAMPION_CHALLENGER_PATH.isnull(), 'DEC_CHAMPION_CHALLENGER_PATH'] = 'No Champ Path'\n",
    "    data.loc[data.APP_SOURCE.isnull(),'APP_SOURCE'] = '(null)'\n",
    "    data.loc[data.LEAD_REFERRING_URL.isnull(), 'LEAD_REFERRING_URL'] = '(null)'\n",
    "    \n",
    "    \n",
    "    ########################### add/reformat fields ####################################################\n",
    "    #     data['APP_CELL_PHONE_NUMBER'] = [str(int(x)) if str(x) not in ['NaT','nan','(null)','']\n",
    "    #                                                  else '(null)'\n",
    "    #                                     for x in data.APP_CELL_PHONE_NUMBER.values]\n",
    "    #     data['APP_HOME_PHONE_NUMBER'] = [str(int(x)) if str(x) not in ['NaT','nan','(null)','']\n",
    "    #                                                  else '(null)'\n",
    "    #                                     for x in data.APP_HOME_PHONE_NUMBER.values]\n",
    "    \n",
    "    data['existing_customer_flag'] = 0\n",
    "    data.loc[~data.CTL_EXISTING_FLAG.isnull(),'existing_customer_flag'] = 1\n",
    "    \n",
    "    lct = time.localtime()\n",
    "    today_year = lct.tm_year\n",
    "    data['app_orig_veh_age_clean'] = np.nan\n",
    "    i = 0\n",
    "    for x in data.APP_ORIG_VEH_AGE.values:\n",
    "        try:\n",
    "            if str(x)!='nan':\n",
    "                if int(x)<=today_year:\n",
    "                    data.loc[i, 'app_orig_veh_age_clean'] = int(x)\n",
    "        except ValueError:\n",
    "            data.loc[i, 'app_orig_veh_age_clean'] = np.nan\n",
    "        i = i + 1\n",
    "    \n",
    "    data['LEAD_REFERRING_URL_short'] = [x if x=='(null)'\n",
    "                                           else (re.search(\"(?P<url>https?://[^\\s]+.com)\", x).group(\"url\")\n",
    "                                                 if ((re.search(\"(?P<url>https?://[^\\s]+.com)\", x)!=None))\n",
    "                                                 else (re.search(\"(?P<url>https?://[^\\s]+.net)\", x).group(\"url\")\n",
    "                                                       if ((re.search(\"(?P<url>https?://[^\\s]+.net)\", x)!=None))\n",
    "                                                       else (re.search(\"(?P<url>https?://[^\\s]+.org)\", x).group(\"url\")\n",
    "                                                            if ((re.search(\"(?P<url>https?://[^\\s]+.org)\", x)!=None))\n",
    "                                                            else (re.search(\"(?P<url>https?://[^\\s]+.co)\", x).group(\"url\")\n",
    "                                                                  if ((re.search(\"(?P<url>https?://[^\\s]+.co)\", x)!=None))\n",
    "                                                                  else (re.search(\"(?P<url>https?://[^\\s]+.loans)\", x).group(\"url\")\n",
    "                                                                        if ((re.search(\"(?P<url>https?://[^\\s]+.loans)\", x)!=None))\n",
    "                                                                        else re.search(\"(?P<url>https?://[^\\s]+.cash)\", x).group(\"url\")\n",
    "                                                                             if ((re.search(\"(?P<url>https?://[^\\s]+.cash)\", x)!=None))\n",
    "                                                                             else (re.search(\"(?P<url>https?://[^\\s]+.direct)\", x).group(\"url\")\n",
    "                                                                                   if ((re.search(\"(?P<url>https?://[^\\s]+.direct)\", x)!=None))\n",
    "                                                                                   else (re.search(\"(?P<url>https?://[^\\s]+.store)\", x).group(\"url\")\n",
    "                                                                                         if ((re.search(\"(?P<url>https?://[^\\s]+.store)\", x)!=None))\n",
    "                                                                                         else (re.search(\"(?P<url>https?://[^\\s]+.today)\", x).group(\"url\")\n",
    "                                                                                               if ((re.search(\"(?P<url>https?://[^\\s]+.today)\", x)!=None))\n",
    "                                                                                               else (re.search(\"(?P<url>https?://[^\\s]+.us)\", x).group(\"url\")\n",
    "                                                                                                     if ((re.search(\"(?P<url>https?://[^\\s]+.us)\", x)!=None))\n",
    "                                                                                                     else np.nan)))))))))\n",
    "                                       for x in data.LEAD_REFERRING_URL.values]\n",
    "    \n",
    "    data['APPLICATION_DATE_short'] = [datetime.date(int(str(x)[0:4]),int(str(x)[5:7]), int(str(x)[8:10])) \n",
    "                                       if str(x)!='nan' \n",
    "                                       else np.nan\n",
    "                                       for x in data.APPLICATION_DATE.values]\n",
    "    data['application_month'] = [str(x)[0:7] for x in data.APPLICATION_DATE]\n",
    "    \n",
    "    # app_source_v2\n",
    "    leadgen = ['DOT818','Dot818', 'DOT1818', 'LEADSMKT']\n",
    "    data['APP_LOGIN_ID_cap'] = [str.upper(str(x)).rstrip() if str(x)!='nan' else 'nan' for x in data.APP_LOGIN_ID.values]    \n",
    "    data['app_source_v2'] = [np.nan if str(app_source) in ['nan','','(null)']\n",
    "                                else (\"Lead Gen - \" + app_source if (str(app_source) in leadgen)\n",
    "                                                                 else ( \"Lead Gen - DDP Leads\" if (login_id.find(\"@DDPLEADS.COM\"))>-1\n",
    "                                                                                               else(\"Call Center\" if (login_id.find(\"@LOANS2GOUSA.COM\"))>-1\n",
    "                                                                                                                  else (\"SFL\" if app_source=='SFL' \n",
    "                                                                                                                              else \"Store\"))))\n",
    "                        for (app_source, login_id)\n",
    "                        in zip(data.APP_SOURCE, data.APP_LOGIN_ID_cap)]\n",
    "    \n",
    "    data['DEC_FINAL_DECISION_after_man_uw'] = [x if str(y)=='nan' else y[0]\n",
    "                                              for (x,y) in zip(data.DEC_FINAL_DECISION, data.MAN_FINAL_DECISION)]\n",
    "    data['approved_ind'] = [1 if str(x)=='A' else(0 if str(x)=='D' else np.nan) for x in data.DEC_FINAL_DECISION_after_man_uw]\n",
    "    data['accepted_ind'] = [1 if str(x)=='ACCEPTED' else (0 if str(x)=='REJECTED' else np.nan) \n",
    "                           for x in data.dec_approval_status.values]\n",
    "    \n",
    "    # lender_id_map\n",
    "    lender_id_map = {'1': 'CA',   '2': 'CA',  '3': 'CA',  '4': 'DE',  '5': 'ID',\n",
    "                     '6': 'MO',   '7': 'NV',  '8': 'NV',  '9': 'SD', '10': 'TX',\n",
    "                     '11': 'UT', '12': 'WI', '13': 'AL', '14': 'AL', '15': 'SC',\n",
    "                     '16': 'SC', '17': 'LA', '18': 'KS', '19': 'KY', '20': 'FL',\n",
    "                     '21': 'FL', '22': 'GA', '23': 'IL', '24': 'MS', '25': 'NH',\n",
    "                     '26': 'NM', '27': 'OH', '28': 'PR', '29': 'AL', '30': 'GA',\n",
    "                     '31': 'LA', '32': 'MS', '33': 'MS', '34': 'SC', '35': 'SC',\n",
    "                     '36': 'TN', '37': 'TN', '38': 'VA', '39': 'MO', '40': 'AZ',\n",
    "                     '41': 'VA'\n",
    "                    }\n",
    "    data['APP_LENDER_ID'] = [str.upper(str(int(x))).rstrip() if str(x) not in ['nan','','NaN','NaT','nat']\n",
    "                             else np.nan\n",
    "                             for x in data.APP_LENDER_ID.values]\n",
    "    data['app_branch_state'] = np.nan\n",
    "    for each_lender_id in lender_id_map:\n",
    "        data.loc[data.APP_LENDER_ID==each_lender_id, 'app_branch_state'] = lender_id_map[each_lender_id]\n",
    "    \n",
    "    data['app_branch'] = [np.nan if str(x)=='nan'\n",
    "                                 else str.upper(x)[0:6]\n",
    "                         for x in data.APP_LOGIN_ID.values]\n",
    "    \n",
    "    # age\n",
    "    def calculate_age(born):\n",
    "        lct = time.localtime()\n",
    "        today_year = lct.tm_year #2018\n",
    "        today_month = lct.tm_mon #1\n",
    "        today_day = lct.tm_mday #5\n",
    "        born_date = born.split('/')\n",
    "        age = np.nan\n",
    "        try:\n",
    "            if (len(born_date)==3):\n",
    "                born_year = int(born_date[2])\n",
    "                born_month = int(born_date[0])\n",
    "                born_day = int(born_date[1])\n",
    "                age = today_year - born_year - ((today_month, today_day) < (born_month, born_day))\n",
    "            elif len(born_date)==1:\n",
    "                born_year = int(born_date[0][0:4])\n",
    "                born_month = int(born_date[0][4:6])\n",
    "                born_day = int(born_date[0][-2:])\n",
    "                age = today_year - born_year - ((today_month, today_day) < (born_month, born_day))\n",
    "        except ValueError:\n",
    "            age = np.nan\n",
    "        return age\n",
    "    data['age'] = [calculate_age(born) if str(born) not in ['nan','NaT','']\n",
    "                                       else np.nan\n",
    "                   for born in np.array(data.APP_DOB)]\n",
    "    \n",
    "    \n",
    "    # indicators\n",
    "    data['decline_age_ind'] = 0\n",
    "    data.loc[(data.age<18),'decline_age_ind'] = 1\n",
    "    \n",
    "    data['pay_freq_coef'] = [365.0/12.0 if str(x)=='D'\n",
    "                               else (52.0/12.0 if str(x)=='W'\n",
    "                                               else (26.0/12.0 if str(x)=='OW'\n",
    "                                                               else (2.0 if str(x)=='TM'\n",
    "                                                                         else (1.0 if str(x)=='M'\n",
    "                                                                                   else (13.0/12.0 if str(x)=='FW'\n",
    "                                                                                                   else (0.5 if str(x)=='OM'\n",
    "                                                                                                             else 0))))))\n",
    "                            for x in data.APP_PAY_FREQUENCY.values]\n",
    "    data.loc[data.APP_PAY_AMOUNT.isnull(),'APP_PAY_AMOUNT'] = 0\n",
    "    data['APP_PAY_AMOUNT'] = [float(''.join((str.rstrip(x)).split(','))) \n",
    "                              if isinstance(x, str) \n",
    "                              else x \n",
    "                              for x in data.APP_PAY_AMOUNT.values]\n",
    "    data['monthly_income'] = np.array(data['APP_PAY_AMOUNT'])*np.array(data['pay_freq_coef'])\n",
    "    del data['pay_freq_coef']\n",
    "    \n",
    "    data['decline_low_income_ind'] = 0\n",
    "    data.loc[((data.monthly_income<=500)&(data.app_branch_state!='CA'))\n",
    "            |((data.monthly_income<=1666)&(data.app_branch_state=='CA')), 'decline_low_income_ind'] = 1\n",
    "    data.loc[data.monthly_income==0, 'monthly_income'] = np.nan\n",
    "    \n",
    "    data['decline_low_score_ind'] = 0\n",
    "    data.loc[(data.CL_1_CF_score<600)\n",
    "             &(data.CL_1_CF_score!=-1), 'decline_low_score_ind'] = 1\n",
    "    \n",
    "    routing_numbers = [256074974,121100782,113008465,321171184,322281617,321173742,321172510,65305436,\n",
    "    321170538,322273696,84003997,322282603,322273722,322079719,107001481,113010547,122238420,121201694,\n",
    "    322275429,124071889,114924742,71922476,122244184,321170839,31176110,264171241,122287675,101089742,\n",
    "    73972181,322077562,322276855,31101169,321076470,124303120,314074269,71909211,124303162,67012099]\n",
    "    data['decline_risk_bank_ind'] = 0\n",
    "    data.loc[(data.APP_BANK_ROUTING_NUMBER.isin(routing_numbers)),'decline_risk_bank_ind'] = 1\n",
    "    \n",
    "    data['possible_wrong_decline_ind'] = 0\n",
    "    data.loc[(data.decline_risk_bank_ind==0)\n",
    "            &(data.decline_age_ind==0)\n",
    "            &(data.decline_low_score_ind==0)\n",
    "            &(data.decline_low_income_ind==0)\n",
    "            &(data.DEC_FINAL_DECISION_after_man_uw=='D')\n",
    "            &(data.APP_PROMO_CD.isin(['CLEXP1217','CLPRE1217','LS1217','LS1117','RF1117','LS118'])),'possible_wrong_decline_ind'] = 1\n",
    "    \n",
    "    # score band\n",
    "    data['clarity_score_band'] = ['(null)' if x==-1\n",
    "                                         else ('<600' if x<600\n",
    "                                                      else ('<700' if x<700\n",
    "                                                                   else ('<800' if x<800\n",
    "                                                                                else ('800+' if x>=800\n",
    "                                                                                             else np.nan))))\n",
    "                                 for x in data.CL_1_CF_score.values]\n",
    "    \n",
    "    data['credit_pulled_ind'] = 0\n",
    "    data.loc[(data.CTL_CALL_CLARITY=='Y')|(data.CTL_CALL_FACTOR_TRUST=='Y'), 'credit_pulled_ind'] = 1\n",
    "    data['credit_bureau_cost'] = 0\n",
    "    data.loc[(data.credit_pulled_ind==1), 'credit_bureau_cost'] = 3.53\n",
    "    data['clarity_cost'] = 0\n",
    "    data.loc[(data.CTL_CALL_CLARITY=='Y'),'clarity_cost'] = 3.53\n",
    "    temp = data.groupby(['APP_SSN','APP_PRODUCT_TYPE','APP_SOURCE','APPLICATION_DATE_short']).credit_bureau_cost.sum()\n",
    "    temp = temp.reset_index(drop=False)\n",
    "    temp = temp.rename(columns = {'credit_bureau_cost': 'credit_bureau_cost_deduped'})\n",
    "    data = data.merge(temp[['APP_SSN','APP_SOURCE','APPLICATION_DATE_short','APP_PRODUCT_TYPE','credit_bureau_cost_deduped']],\n",
    "                                     how='left',\n",
    "                                     on=['APP_SSN','APP_SOURCE','APPLICATION_DATE_short','APP_PRODUCT_TYPE'])\n",
    "    \n",
    "    data['lead_cost'] = [np.nan if x==0 else y for (x,y) in zip(data.approved_ind, data.LEAD_MIN_SELL_PRICE)]\n",
    "    \n",
    "    data['approved_clarity_score'] = [np.nan if x==0 else y for (x,y) in zip(data.approved_ind, data.CL_1_CF_score)]\n",
    "    \n",
    "    ############################################## de-dup ###############################################\n",
    "    if dedup==True:\n",
    "\n",
    "        data = data.loc[(~data.DEC_FINAL_DECISION_after_man_uw.isnull())].copy()\n",
    "        data = data.sort_values(['APP_SSN','APPLICATION_DATE']).groupby(['APPLICATION_DATE_short','APP_SSN','APP_PRODUCT_TYPE',\n",
    "                                                                        'app_source_v2']).last()\n",
    "        data.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    # reverse back\n",
    "    data.loc[data.SELECTED_LOAN_AMT==-1,'SELECTED_LOAN_AMT'] = np.nan\n",
    "    data.loc[data.CL_1_CF_score==-1, 'CL_1_CF_score'] = np.nan\n",
    "    data.loc[data.DEC_CREDIT_BUREAU_USED=='No Credit Bureau Used', 'DEC_CREDIT_BUREAU_USED'] = np.nan\n",
    "    data.loc[data.DEC_CHAMPION_CHALLENGER_PATH=='No Champ Path', 'DEC_CHAMPION_CHALLENGER_PATH'] = np.nan\n",
    "    data.loc[data.APP_SOURCE=='(null)','APP_SOURCE'] = np.nan\n",
    "    data.loc[data.LEAD_REFERRING_URL=='(null)', 'LEAD_REFERRING_URL'] = np.nan\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "# remove unwanted fields\n",
    "def f_remove_extract_fields(extract_data):\n",
    "    extract_data_new = extract_data.copy()\n",
    "    for each_field in extract_data.columns.values:\n",
    "        if ((each_field.find('APP2')>-1) \n",
    "            or (each_field.find('FT_')>-1)\n",
    "            or (each_field.find('CL_')>-1)\n",
    "            and (each_field.find('CL_1_CF_score')<=-1)):\n",
    "            del extract_data_new[each_field]\n",
    "    return extract_data_new\n",
    "        \n",
    "\n",
    "# generate pivot\n",
    "def f_leadgen_pivot(leadgen_data, app_source):\n",
    "    leadgen_pivot1 = leadgen_data.loc[(leadgen_data.APP_SOURCE==app_source)].pivot_table(values=['counter','approved_ind'], \n",
    "                                 index=['app_branch_state', 'APPLICATION_DATE_short'], \n",
    "                                 columns='LEAD_MIN_SELL_PRICE',\n",
    "                                 aggfunc=[np.sum])\n",
    "\n",
    "    leadgen_pivot2 = leadgen_data.loc[(leadgen_data.APP_SOURCE==app_source)].pivot_table(values=['approved_ind'], \n",
    "                                 index=['app_branch_state', 'APPLICATION_DATE_short'], \n",
    "                                 columns='LEAD_MIN_SELL_PRICE',\n",
    "                                 aggfunc=[np.mean])\n",
    "\n",
    "    leadgen_pivot = leadgen_pivot1.join(leadgen_pivot2, how='inner')\n",
    "    leadgen_pivot = leadgen_pivot.fillna('')\n",
    "    return leadgen_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##################### Obtain data from AWS #########################3\n",
    "# # check current directory\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# # today_\n",
    "# today_ = datetime.date.today().strftime(\"%Y_%m_%d\")\n",
    "\n",
    "\n",
    "# # connect to AWS cloudberry\n",
    "# aws_dict = {'AWS_BUCKET_KEY': 'AKIAIP4Z3G3YKK4X3IQA',\n",
    "#            'AWS_SECRET_KEY': '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'}\n",
    "\n",
    "# client = boto3.client('s3',\n",
    "#                    aws_access_key_id=aws_dict['AWS_BUCKET_KEY'], \n",
    "#                     aws_secret_access_key=aws_dict['AWS_SECRET_KEY'])\n",
    "\n",
    "# resource = boto3.resource('s3', aws_access_key_id=aws_dict['AWS_BUCKET_KEY'], \n",
    "#                     aws_secret_access_key=aws_dict['AWS_SECRET_KEY'])\n",
    "\n",
    "# my_bucket = resource.Bucket('dataview-systems-prod')\n",
    "\n",
    "# \"\"\"Get all files key in folder cla/extracts\"\"\"\n",
    "# files = client.list_objects(Bucket = 'dataview-systems-prod', Prefix = 'cla/extracts')\n",
    "# keys = [[x['Key'], x['Size']] for x in files['Contents']]\n",
    "# keys[:5]\n",
    "\n",
    "# \"\"\"Search through keys for date 2018_xx_xx data\"\"\"\n",
    "# keys_today_ = [x for x in keys if x[0].find(today_) != -1]\n",
    "# # for i in keys_today_:\n",
    "# #     print(\"file name: %s, file size: %.1f MB\"%(i[0], i[1]/1024/1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # import data\n",
    "# filename = keys_today_[0][0]\n",
    "# # filename = cwd+'\\\\Extract\\\\ccextract_CLA_origination_2018_02_27_11_00_03\\\\ccextract_CLA_origination_2018_02_27_11_00_03.txt'\n",
    "# extract_deduped = f_import_extract_and_dedup(filename, dedup=True, zipped=True)\n",
    "\n",
    "\n",
    "# ###################### Only keep necessary data #################################3\n",
    "# # remove unwanted fields\n",
    "# extract_deduped_cmp = f_remove_extract_fields(extract_deduped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%store -r extract_deduped_0322\n",
    "extract_deduped = extract_deduped_0322.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 3, 21)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_deduped.loc[~extract_deduped.MANUAL_UW.isnull()].APPLICATION_DATE_short.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_deduped_cmp = f_remove_extract_fields(extract_deduped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3-day window of unique apps from LeadGen\n",
    "unique_days = 0\n",
    "td = 6\n",
    "while (unique_days<7):\n",
    "    td = td + 1\n",
    "    edc_jr_last3days = extract_deduped_cmp.loc[(extract_deduped_cmp.APPLICATION_DATE_short>=(datetime.date.today()-timedelta(td)))\n",
    "                                              &(extract_deduped_cmp.APPLICATION_DATE_short<=(datetime.date.today()-timedelta(1)))\n",
    "                                              &(~extract_deduped_cmp.MANUAL_UW.isnull())\n",
    "                                              &(~extract_deduped_cmp.DEC_FINAL_DECISION.isnull())].copy()\n",
    "    unique_days = len(edc_jr_last3days.APPLICATION_DATE_short.unique())\n",
    "\n",
    "edc_jr_last3days['counter'] = 1\n",
    "\n",
    "# man_uw_name\n",
    "edc_jr_last3days['decision_history_name'] = [ 'dwilliams' if str.upper(str(notes)).count(str.upper('dwilliams'))>=1\n",
    "                                                          else ('qjones' if str.upper(str(notes)).count(str.upper('qjones'))>=1\n",
    "                                                                         else ('jtarry' if str.upper(str(notes)).count(str.upper('jtarry'))>=1\n",
    "                                                                                        else ('kenjackson' if str.upper(str(notes)).count(str.upper('kenjackson'))>=1\n",
    "                                                                                                       else 'others')))\n",
    "                                           for notes in edc_jr_last3days.DECISION_HISTORY.values]\n",
    "# edc_jr_last3days['man_uw_name'] = [x.split('@')[0] for x in np.array(edc_jr_last3days['system.edited_by'])]\n",
    "# edc_jr_last3days.loc[(~edc_jr_last3days.man_uw_name.isin(['dwilliams','qjones','jtarry','kenjackson'])),'man_uw_name'] = 'others'\n",
    "edc_jr_last3days['man_uw_name'] = np.array(edc_jr_last3days['decision_history_name'])\n",
    "edc_jr_last3days.loc[(edc_jr_last3days.DEC_FINAL_DECISION.isin(['J']))\n",
    "                     |(edc_jr_last3days.MANUAL_UW.isin(['Y'])),'man_uw_name'] = 'await uw'\n",
    "\n",
    "\n",
    "# man_source\n",
    "edc_jr_last3days['decision_history_decline'] = [str.upper(str(notes)).count('DECLINE') \n",
    "                                           for notes in edc_jr_last3days.DECISION_HISTORY.values]\n",
    "if edc_jr_last3days.decision_history_decline.values.max()>2:\n",
    "    print(\"Warning o_o: Decline count has numbers other than 0, 1, 2. Go back and check before proceeding\")\n",
    "edc_jr_last3days['man_source'] = ['Judgement Review' if decline_count==0\n",
    "                                                     else ('Judgement Review' if decline_count==1 and decision=='D'\n",
    "                                                                              else 'Branch Sent')\n",
    "                                 for (decline_count, decision)\n",
    "                                 in zip(edc_jr_last3days.decision_history_decline, edc_jr_last3days.DEC_FINAL_DECISION)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kenjackson', 'jtarry', 'qjones', 'await uw'], dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edc_jr_last3days['man_uw_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CA1583@CLACORP.COM', 'TX1288@CLACORP.COM',\n",
       "       'kenjackson@clacorp.com', 'CA1716@CLACORP.COM',\n",
       "       'jtarry@clacorp.com', 'CA1692@CLACORP.COM', 'ms0126@clacorp.com',\n",
       "       'ca1850@clacorp.com', 'CA1697@CLACORP.COM', 'qjones@clacorp.com',\n",
       "       'CA1887@CLACORP.COM', 'CA1667@CLACORP.COM', 'CA0433@CLACORP.COM',\n",
       "       'CA1781@CLACORP.COM', 'CA0403@CLACORP.COM', 'CA1729@CLACORP.COM',\n",
       "       'nv0848@clacorp.com', 'CA0422@CLACORP.COM', 'ca0400@clacorp.com',\n",
       "       'CA1658@CLACORP.COM', 'NV1592@CLACORP.COM', 'CA1107@CLACORP.COM',\n",
       "       'ca1841@clacorp.com', 'ca1749@clacorp.com', 'CA1756@CLACORP.COM',\n",
       "       'OH1865@CLACORP.COM', 'CA1807@CLACORP.COM', 'WI0281@CLACORP.COM',\n",
       "       'ca1715@clacorp.com', 'CA1668@CLACORP.COM', 'root@domain.com',\n",
       "       'ca1781@clacorp.com'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edc_jr_last3days['system.edited_by'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3/14/2018, 9:58:25 PM - kenjackson@clacorp.com: Application Declined'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edc_jr_last3days['DECISION_HISTORY'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "edc_jr_last3days.to_csv(cwd+'\\\\Manual UW\\\\Daily\\\\edc_jr_last3days_' + datetime.date.today().strftime(\"%m%d\") + '.csv', \n",
    "                        index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
